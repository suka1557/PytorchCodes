{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import sleep\n",
    "#from Ipython.display import clear_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/fashion-mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      0       0       0       0       0       0       0       0       9   \n",
       "1      1       0       0       0       0       0       0       0       0   \n",
       "2      2       0       0       0       0       0       0      14      53   \n",
       "3      2       0       0       0       0       0       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       8  ...       103        87        56         0         0         0   \n",
       "1       0  ...        34         0         0         0         0         0   \n",
       "2      99  ...         0         0         0         0        63        53   \n",
       "3       0  ...       137       126       140         0       133       224   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2        31         0         0         0  \n",
       "3       222        56         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['label'], axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(['label'], axis = 1).values\n",
    "y_test = test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 16,  36, 226, 164, 227, 230, 224, 255, 254, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 222, 220, 239, 255,\n",
       "       180, 189, 105, 167, 219, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 194, 206, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 211, 189, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 212, 188, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 237, 232, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 227,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 236, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 249, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 245, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 253, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 250,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 244, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 252, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 246, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       245, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 233, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 248, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 233, 233, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 233, 245, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 239, 227, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 248,\n",
       "       227, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 246,  81, 239, 230, 252, 250, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n",
       "       255, 255, 255, 170], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the maximum values across each pixel\n",
    "X_train.max(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing pixel values by dividing 255\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing into tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating tensor datasets using dataset class\n",
    "train = TensorDataset(X_train, y_train)\n",
    "test = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataset.TensorDataset"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.2431, 0.2392, 0.0824, 0.1137, 0.0902,\n",
       "         0.2000, 0.5333, 0.2392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.3451, 0.7882, 0.8941, 0.8824, 1.0000, 0.4510, 0.2431,\n",
       "         0.5373, 1.0000, 0.9216, 0.8706, 1.0000, 0.5294, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.1843, 0.9882, 0.9176, 0.9333, 0.8784, 0.8431, 0.8431, 0.8980,\n",
       "         0.4235, 0.7059, 0.8118, 0.8392, 0.8784, 0.9059, 0.9765, 0.9961, 0.1765,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039,\n",
       "         0.0000, 0.0000, 0.8392, 0.8706, 0.8235, 0.8353, 0.8784, 0.8824, 0.8510,\n",
       "         0.8627, 0.9961, 0.9137, 0.8588, 0.8667, 0.8510, 0.8745, 0.8667, 0.9412,\n",
       "         0.9961, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000,\n",
       "         0.0000, 0.0000, 0.5020, 0.9294, 0.8118, 0.8784, 0.8784, 0.8118, 0.8471,\n",
       "         0.8392, 0.8235, 0.8157, 0.8275, 0.8667, 0.8157, 0.8588, 0.8353, 0.8863,\n",
       "         0.8275, 0.9294, 0.5882, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0078, 0.0000, 0.0000, 0.9294, 0.8706, 0.8431, 0.8118, 0.8235, 0.8314,\n",
       "         0.8353, 0.8078, 0.8392, 0.8353, 0.8392, 0.8353, 0.8235, 0.8431, 0.8392,\n",
       "         0.8078, 0.7804, 0.8549, 1.0000, 0.0510, 0.0000, 0.0078, 0.0000, 0.0000,\n",
       "         0.0000, 0.0157, 0.0000, 0.3333, 0.8941, 0.8235, 0.8549, 0.7843, 0.8275,\n",
       "         0.8157, 0.7961, 0.8431, 0.8235, 0.8196, 0.8196, 0.8235, 0.8353, 0.8275,\n",
       "         0.8235, 0.8510, 0.8078, 0.8353, 0.9059, 0.6863, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.8510, 0.8784, 0.8431, 0.8078, 0.8039,\n",
       "         0.8000, 0.8510, 0.9020, 0.8706, 0.8431, 0.8784, 0.9137, 0.8941, 0.9098,\n",
       "         0.8941, 0.8784, 0.8118, 0.8314, 0.8431, 0.8353, 0.8980, 0.1216, 0.0000,\n",
       "         0.0157, 0.0000, 0.0039, 0.0000, 0.0824, 0.8824, 0.8314, 0.8314, 0.7961,\n",
       "         0.8275, 0.8824, 0.7569, 0.5451, 0.5333, 0.7647, 0.5765, 0.6118, 0.5451,\n",
       "         0.5020, 0.6353, 0.7725, 0.8745, 0.8118, 0.8627, 0.8353, 0.9098, 0.6941,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4824, 0.8863, 0.8118, 0.8275,\n",
       "         0.8196, 0.8039, 0.8941, 0.6196, 0.3529, 0.4039, 0.7294, 0.5412, 0.3922,\n",
       "         0.4745, 0.5765, 0.6196, 0.7176, 0.8863, 0.8157, 0.8392, 0.8196, 0.8471,\n",
       "         1.0000, 0.0510, 0.0000, 0.0039, 0.0000, 0.0000, 0.8863, 0.8588, 0.7922,\n",
       "         0.8157, 0.8078, 0.8039, 0.8471, 0.7216, 0.6118, 0.5882, 0.7569, 0.6667,\n",
       "         0.6431, 0.6588, 0.7373, 0.7294, 0.7843, 0.8588, 0.8471, 0.8353, 0.8353,\n",
       "         0.8275, 0.9137, 0.5804, 0.0000, 0.0000, 0.0000, 0.1765, 0.8902, 0.8000,\n",
       "         0.8392, 0.8275, 0.8549, 0.8706, 0.8667, 0.9020, 0.8980, 0.8667, 0.8353,\n",
       "         0.8784, 0.9137, 0.8863, 0.8627, 0.8588, 0.8667, 0.8784, 0.8745, 0.8510,\n",
       "         0.8235, 0.8549, 0.8353, 0.9961, 0.0000, 0.0000, 0.0000, 0.6157, 0.8863,\n",
       "         0.7961, 0.8118, 0.8275, 0.8196, 0.8431, 0.8039, 0.7765, 0.8118, 0.8157,\n",
       "         0.7882, 0.7882, 0.7725, 0.7961, 0.8039, 0.8235, 0.8118, 0.8353, 0.8392,\n",
       "         0.8392, 0.8392, 0.8353, 0.8157, 0.9176, 0.4196, 0.0000, 0.0000, 0.9216,\n",
       "         0.8353, 0.8000, 0.8275, 0.8235, 0.8196, 0.8353, 0.7922, 0.7725, 0.8000,\n",
       "         0.8431, 0.8510, 0.8353, 0.8314, 0.8235, 0.8078, 0.8314, 0.7961, 0.8275,\n",
       "         0.8549, 0.8431, 0.8392, 0.8157, 0.8196, 0.8706, 0.9020, 0.0000, 0.2039,\n",
       "         1.0000, 0.8118, 0.7843, 0.8157, 0.8353, 0.8235, 0.8235, 0.8157, 0.8118,\n",
       "         0.7922, 0.7882, 0.8196, 0.8471, 0.8471, 0.8471, 0.8471, 0.8392, 0.8314,\n",
       "         0.8039, 0.8431, 0.7882, 0.8941, 0.8157, 0.8392, 0.8314, 0.8549, 0.0980,\n",
       "         0.4627, 0.8510, 0.7882, 0.8078, 0.8157, 0.8353, 0.8157, 0.8039, 0.8078,\n",
       "         0.8235, 0.8275, 0.7922, 0.7804, 0.8118, 0.8157, 0.8196, 0.8235, 0.8118,\n",
       "         0.8235, 0.8235, 0.9608, 0.5451, 0.4667, 1.0000, 0.7922, 0.7961, 0.9255,\n",
       "         0.4471, 0.6706, 0.9333, 0.8314, 0.7961, 0.8627, 0.8471, 0.8510, 0.8196,\n",
       "         0.8118, 0.8039, 0.8235, 0.8275, 0.8078, 0.8000, 0.8078, 0.8196, 0.8275,\n",
       "         0.8431, 0.8235, 0.8078, 0.8667, 0.9490, 0.0000, 0.8784, 0.9176, 0.9020,\n",
       "         0.7098, 0.1020, 0.1529, 0.5686, 0.7882, 1.0000, 0.6157, 0.4510, 0.9804,\n",
       "         0.7843, 0.8118, 0.8078, 0.8118, 0.8353, 0.8471, 0.8078, 0.8039, 0.8078,\n",
       "         0.8118, 0.8078, 0.8431, 0.8118, 0.8667, 0.9333, 0.0000, 0.0000, 0.7373,\n",
       "         0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1216, 0.0000, 0.5059,\n",
       "         0.9922, 0.7451, 0.8118, 0.8157, 0.8157, 0.8157, 0.8196, 0.8275, 0.8275,\n",
       "         0.8196, 0.8196, 0.8196, 0.8314, 0.7882, 0.8863, 0.6471, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.3490, 0.9961, 0.7804, 0.7804, 0.7529, 0.7686, 0.7765, 0.7804, 0.7882,\n",
       "         0.7922, 0.7961, 0.8000, 0.7961, 0.7961, 0.7843, 0.8706, 0.6078, 0.0000,\n",
       "         0.0118, 0.0118, 0.0118, 0.0078, 0.0000, 0.0000, 0.0000, 0.0039, 0.0196,\n",
       "         0.0000, 0.0000, 1.0000, 0.8549, 0.8863, 0.9098, 0.8941, 0.8784, 0.8706,\n",
       "         0.8627, 0.8588, 0.8588, 0.8510, 0.8667, 0.8627, 0.8314, 0.9255, 0.3725,\n",
       "         0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.6078, 0.7608, 0.6588, 0.6667, 0.6706, 0.6784,\n",
       "         0.6784, 0.7020, 0.6941, 0.6863, 0.6745, 0.6706, 0.6549, 0.6314, 0.7059,\n",
       "         0.0000, 0.0000, 0.0039, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000]), tensor(2))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0] # Tuple containing two tensors - one is data and other is label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.2431, 0.2392, 0.0824, 0.1137, 0.0902,\n",
       "        0.2000, 0.5333, 0.2392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.3451, 0.7882, 0.8941, 0.8824, 1.0000, 0.4510, 0.2431,\n",
       "        0.5373, 1.0000, 0.9216, 0.8706, 1.0000, 0.5294, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.1843, 0.9882, 0.9176, 0.9333, 0.8784, 0.8431, 0.8431, 0.8980,\n",
       "        0.4235, 0.7059, 0.8118, 0.8392, 0.8784, 0.9059, 0.9765, 0.9961, 0.1765,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039,\n",
       "        0.0000, 0.0000, 0.8392, 0.8706, 0.8235, 0.8353, 0.8784, 0.8824, 0.8510,\n",
       "        0.8627, 0.9961, 0.9137, 0.8588, 0.8667, 0.8510, 0.8745, 0.8667, 0.9412,\n",
       "        0.9961, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000,\n",
       "        0.0000, 0.0000, 0.5020, 0.9294, 0.8118, 0.8784, 0.8784, 0.8118, 0.8471,\n",
       "        0.8392, 0.8235, 0.8157, 0.8275, 0.8667, 0.8157, 0.8588, 0.8353, 0.8863,\n",
       "        0.8275, 0.9294, 0.5882, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0078, 0.0000, 0.0000, 0.9294, 0.8706, 0.8431, 0.8118, 0.8235, 0.8314,\n",
       "        0.8353, 0.8078, 0.8392, 0.8353, 0.8392, 0.8353, 0.8235, 0.8431, 0.8392,\n",
       "        0.8078, 0.7804, 0.8549, 1.0000, 0.0510, 0.0000, 0.0078, 0.0000, 0.0000,\n",
       "        0.0000, 0.0157, 0.0000, 0.3333, 0.8941, 0.8235, 0.8549, 0.7843, 0.8275,\n",
       "        0.8157, 0.7961, 0.8431, 0.8235, 0.8196, 0.8196, 0.8235, 0.8353, 0.8275,\n",
       "        0.8235, 0.8510, 0.8078, 0.8353, 0.9059, 0.6863, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.8510, 0.8784, 0.8431, 0.8078, 0.8039,\n",
       "        0.8000, 0.8510, 0.9020, 0.8706, 0.8431, 0.8784, 0.9137, 0.8941, 0.9098,\n",
       "        0.8941, 0.8784, 0.8118, 0.8314, 0.8431, 0.8353, 0.8980, 0.1216, 0.0000,\n",
       "        0.0157, 0.0000, 0.0039, 0.0000, 0.0824, 0.8824, 0.8314, 0.8314, 0.7961,\n",
       "        0.8275, 0.8824, 0.7569, 0.5451, 0.5333, 0.7647, 0.5765, 0.6118, 0.5451,\n",
       "        0.5020, 0.6353, 0.7725, 0.8745, 0.8118, 0.8627, 0.8353, 0.9098, 0.6941,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4824, 0.8863, 0.8118, 0.8275,\n",
       "        0.8196, 0.8039, 0.8941, 0.6196, 0.3529, 0.4039, 0.7294, 0.5412, 0.3922,\n",
       "        0.4745, 0.5765, 0.6196, 0.7176, 0.8863, 0.8157, 0.8392, 0.8196, 0.8471,\n",
       "        1.0000, 0.0510, 0.0000, 0.0039, 0.0000, 0.0000, 0.8863, 0.8588, 0.7922,\n",
       "        0.8157, 0.8078, 0.8039, 0.8471, 0.7216, 0.6118, 0.5882, 0.7569, 0.6667,\n",
       "        0.6431, 0.6588, 0.7373, 0.7294, 0.7843, 0.8588, 0.8471, 0.8353, 0.8353,\n",
       "        0.8275, 0.9137, 0.5804, 0.0000, 0.0000, 0.0000, 0.1765, 0.8902, 0.8000,\n",
       "        0.8392, 0.8275, 0.8549, 0.8706, 0.8667, 0.9020, 0.8980, 0.8667, 0.8353,\n",
       "        0.8784, 0.9137, 0.8863, 0.8627, 0.8588, 0.8667, 0.8784, 0.8745, 0.8510,\n",
       "        0.8235, 0.8549, 0.8353, 0.9961, 0.0000, 0.0000, 0.0000, 0.6157, 0.8863,\n",
       "        0.7961, 0.8118, 0.8275, 0.8196, 0.8431, 0.8039, 0.7765, 0.8118, 0.8157,\n",
       "        0.7882, 0.7882, 0.7725, 0.7961, 0.8039, 0.8235, 0.8118, 0.8353, 0.8392,\n",
       "        0.8392, 0.8392, 0.8353, 0.8157, 0.9176, 0.4196, 0.0000, 0.0000, 0.9216,\n",
       "        0.8353, 0.8000, 0.8275, 0.8235, 0.8196, 0.8353, 0.7922, 0.7725, 0.8000,\n",
       "        0.8431, 0.8510, 0.8353, 0.8314, 0.8235, 0.8078, 0.8314, 0.7961, 0.8275,\n",
       "        0.8549, 0.8431, 0.8392, 0.8157, 0.8196, 0.8706, 0.9020, 0.0000, 0.2039,\n",
       "        1.0000, 0.8118, 0.7843, 0.8157, 0.8353, 0.8235, 0.8235, 0.8157, 0.8118,\n",
       "        0.7922, 0.7882, 0.8196, 0.8471, 0.8471, 0.8471, 0.8471, 0.8392, 0.8314,\n",
       "        0.8039, 0.8431, 0.7882, 0.8941, 0.8157, 0.8392, 0.8314, 0.8549, 0.0980,\n",
       "        0.4627, 0.8510, 0.7882, 0.8078, 0.8157, 0.8353, 0.8157, 0.8039, 0.8078,\n",
       "        0.8235, 0.8275, 0.7922, 0.7804, 0.8118, 0.8157, 0.8196, 0.8235, 0.8118,\n",
       "        0.8235, 0.8235, 0.9608, 0.5451, 0.4667, 1.0000, 0.7922, 0.7961, 0.9255,\n",
       "        0.4471, 0.6706, 0.9333, 0.8314, 0.7961, 0.8627, 0.8471, 0.8510, 0.8196,\n",
       "        0.8118, 0.8039, 0.8235, 0.8275, 0.8078, 0.8000, 0.8078, 0.8196, 0.8275,\n",
       "        0.8431, 0.8235, 0.8078, 0.8667, 0.9490, 0.0000, 0.8784, 0.9176, 0.9020,\n",
       "        0.7098, 0.1020, 0.1529, 0.5686, 0.7882, 1.0000, 0.6157, 0.4510, 0.9804,\n",
       "        0.7843, 0.8118, 0.8078, 0.8118, 0.8353, 0.8471, 0.8078, 0.8039, 0.8078,\n",
       "        0.8118, 0.8078, 0.8431, 0.8118, 0.8667, 0.9333, 0.0000, 0.0000, 0.7373,\n",
       "        0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1216, 0.0000, 0.5059,\n",
       "        0.9922, 0.7451, 0.8118, 0.8157, 0.8157, 0.8157, 0.8196, 0.8275, 0.8275,\n",
       "        0.8196, 0.8196, 0.8196, 0.8314, 0.7882, 0.8863, 0.6471, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.3490, 0.9961, 0.7804, 0.7804, 0.7529, 0.7686, 0.7765, 0.7804, 0.7882,\n",
       "        0.7922, 0.7961, 0.8000, 0.7961, 0.7961, 0.7843, 0.8706, 0.6078, 0.0000,\n",
       "        0.0118, 0.0118, 0.0118, 0.0078, 0.0000, 0.0000, 0.0000, 0.0039, 0.0196,\n",
       "        0.0000, 0.0000, 1.0000, 0.8549, 0.8863, 0.9098, 0.8941, 0.8784, 0.8706,\n",
       "        0.8627, 0.8588, 0.8588, 0.8510, 0.8667, 0.8627, 0.8314, 0.9255, 0.3725,\n",
       "        0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.6078, 0.7608, 0.6588, 0.6667, 0.6706, 0.6784,\n",
       "        0.6784, 0.7020, 0.6941, 0.6863, 0.6745, 0.6706, 0.6549, 0.6314, 0.7059,\n",
       "        0.0000, 0.0000, 0.0039, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only data\n",
    "train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only label\n",
    "train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining training and test loader\n",
    "train_loader = DataLoader(train, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size = 128, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Neural Network\n",
    "#Input --> h1 --> h2 --> h3 --> h4 -->h5 -->out\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features = 784, h1 = 8, h2 = 16, h3 = 32, h4 = 64, h5 = 128, out_features = 10):\n",
    "        super(Model ,  self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, h1)\n",
    "        self.fc2 = nn.Linear(h1,h2)\n",
    "        self.fc3 = nn.Linear(h2,h3)\n",
    "        self.fc4 = nn.Linear(h3,h4)\n",
    "        self.fc5 = nn.Linear(h4,h5)\n",
    "        self.out = nn.Linear(h5, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.log_softmax(self.out(x))\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Model(\n",
      "  (fc1): Linear(in_features=784, out_features=8, bias=True)\n",
      "  (fc2): Linear(in_features=8, out_features=16, bias=True)\n",
      "  (fc3): Linear(in_features=16, out_features=32, bias=True)\n",
      "  (fc4): Linear(in_features=32, out_features=64, bias=True)\n",
      "  (fc5): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (out): Linear(in_features=128, out_features=10, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(network.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining loss and optimizer and EPOCHS\n",
    "loss_criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr = 0.01)\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suka1\\Anaconda3\\envs\\pytorchenv\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 -  loss_values: 0.4981432855129242 - accuracy: 0.8125\n",
      "Epoch: 2 -  loss_values: 0.43666860461235046 - accuracy: 0.84375\n",
      "Epoch: 3 -  loss_values: 0.5663291811943054 - accuracy: 0.7395833134651184\n",
      "Epoch: 4 -  loss_values: 0.5193310379981995 - accuracy: 0.7708333134651184\n",
      "Epoch: 5 -  loss_values: 0.4536900818347931 - accuracy: 0.8125\n"
     ]
    }
   ],
   "source": [
    "loss_values = list()\n",
    "accuracy_values = list()\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    for j, data in enumerate(train_loader):\n",
    "        x, y = data[0].reshape(-1, 784) , data[1]\n",
    "        y_pred = network.forward(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss = loss_criterion( y_pred , y)\n",
    "        accuracy = (torch.sum((torch.argmax(y_pred, 1) == y).float()))/y_pred.shape[0]\n",
    "        \n",
    "        \n",
    "        #appending loss & accuracy values\n",
    "        loss_values.append(loss)\n",
    "        accuracy_values.append(accuracy)\n",
    "        \n",
    "        #Zeroing gradient\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #doing backward propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        #updating parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    #Looking at shapes of predicted and actual outputs\n",
    "    #print(y_pred.shape , y.shape)\n",
    "    \n",
    "    #printing loss values after every epoch\n",
    "    print('Epoch: {} -  loss_values: {} - accuracy: {}'.format(i+1,  loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Evolution of Loss Values\n",
    "plt.plot(range(len(loss_values)), loss_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suka1\\Anaconda3\\envs\\pytorchenv\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "# Doing Prediction on test data\n",
    "correct_points = 0\n",
    "total_points = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        x, y = data[0].reshape(-1, 784) , data[1]\n",
    "        y_pred = network.forward(x)\n",
    "        \n",
    "        correct_points += torch.sum((torch.argmax(y_pred, 1) == y).float())\n",
    "        total_points += y.shape[0]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8401.)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set:  0.8400999903678894\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on test set: ', (correct_points/total_points).item() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
